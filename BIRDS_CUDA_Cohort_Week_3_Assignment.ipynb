{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taqihaider7/C4AI-BIRDS-CUDA-Programming/blob/master/BIRDS_CUDA_Cohort_Week_3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Write a simple CUDA kernel that takes an array of integers and doubles each element.**"
      ],
      "metadata": {
        "id": "3n714FyEdcaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! touch add_basic.cu\n",
        "\n",
        "\"\"\"\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void doubleArray(int* arr, int n)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n)\n",
        "    {\n",
        "        arr[idx] *= 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 100; // size of the array\n",
        "    int* arr;\n",
        "    cudaMalloc((void**)&arr, n * sizeof(int));\n",
        "\n",
        "    // initialize the array\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        arr[i] = i;\n",
        "    }\n",
        "\n",
        "    // copy the array to the GPU\n",
        "    cudaMemcpy(arr, arr, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // launch the kernel\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
        "    doubleArray<<<numBlocks, blockSize>>>(arr, n);\n",
        "\n",
        "    // copy the result back to the host\n",
        "    cudaMemcpy(arr, arr, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print the result\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        printf(\"%d \", arr[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // free the memory\n",
        "    cudaFree(arr);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "fy9AuUNBAOgL",
        "outputId": "5c982de9-b7d1-4087-c808-150b9d2067cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#include <stdio.h>\\n#include <cuda_runtime.h>\\n\\n__global__ void doubleArray(int* arr, int n) \\n{\\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\\n    if (idx < n) \\n    {\\n        arr[idx] *= 2;\\n    }\\n}\\n\\nint main() \\n{\\n    int n = 100; // size of the array\\n    int* arr;\\n    cudaMalloc((void**)&arr, n * sizeof(int));\\n\\n    // initialize the array\\n    for (int i = 0; i < n; i++) \\n    {\\n        arr[i] = i;\\n    }\\n\\n    // copy the array to the GPU\\n    cudaMemcpy(arr, arr, n * sizeof(int), cudaMemcpyHostToDevice);\\n\\n    // launch the kernel\\n    int blockSize = 256;\\n    int numBlocks = (n + blockSize - 1) / blockSize;\\n    doubleArray<<<numBlocks, blockSize>>>(arr, n);\\n\\n    // copy the result back to the host\\n    cudaMemcpy(arr, arr, n * sizeof(int), cudaMemcpyDeviceToHost);\\n\\n    // print the result\\n    for (int i = 0; i < n; i++) \\n    {\\n        printf(\"%d \", arr[i]);\\n    }\\n    printf(\"\\n\");\\n\\n    // free the memory\\n    cudaFree(arr);\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Write a CUDA kernel to initialize an array of integers with the index value.**"
      ],
      "metadata": {
        "id": "8IFT0vwhdhKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! touch add_basic.cu\n",
        "\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void initialize_array(int *array)\n",
        "{\n",
        "    // Calculate the index for the current thread\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Initialize the array element at the calculated index with its index value\n",
        "    array[index] = index;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int array_size = 10;\n",
        "    int *d_array;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_array, array_size * sizeof(int));\n",
        "\n",
        "    // Launch the CUDA kernel to initialize the array\n",
        "    // Specify 1 block with 10 threads, assuming array_size is small for simplicity\n",
        "    initialize_array<<<1, array_size>>>(d_array);\n",
        "\n",
        "    // Copy data from device to host\n",
        "    int h_array[array_size];\n",
        "    cudaMemcpy(h_array, d_array, array_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the initialized array\n",
        "    cout << \"Initialized Array:\" << endl;\n",
        "    for (int i = 0; i < array_size; ++i) {\n",
        "        cout << h_array[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_array);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "KNb7UnP4aUX0",
        "outputId": "6384fb41-1d61-4ec6-e921-8b4dfaccd2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#include <iostream>\\n#include <cuda_runtime.h>\\n\\nusing namespace std;\\n\\n__global__ void initialize_array(int *array)\\n{\\n    // Calculate the index for the current thread\\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\\n\\n    // Initialize the array element at the calculated index with its index value\\n    array[index] = index;\\n}\\n\\nint main()\\n{\\n    const int array_size = 10;\\n    int *d_array;\\n\\n    // Allocate memory on GPU\\n    cudaMalloc((void**)&d_array, array_size * sizeof(int));\\n\\n    // Launch the CUDA kernel to initialize the array\\n    // Specify 1 block with 10 threads, assuming array_size is small for simplicity\\n    initialize_array<<<1, array_size>>>(d_array);\\n\\n    // Copy data from device to host\\n    int h_array[array_size];\\n    cudaMemcpy(h_array, d_array, array_size * sizeof(int), cudaMemcpyDeviceToHost);\\n\\n    // Print the initialized array\\n    cout << \"Initialized Array:\" << endl;\\n    for (int i = 0; i < array_size; ++i) {\\n        cout << h_array[i] << \" \";\\n    }\\n    cout << endl;\\n\\n    // Free GPU memory\\n    cudaFree(d_array);\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3 [OPTIONAL]. How do you check for and handle errors in CUDA API calls and kernel launches?**"
      ],
      "metadata": {
        "id": "8uewwr30fg-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA API calls: Use the return value of each CUDA API call and compare it against \"cudaSuccess\"\n",
        "\n",
        "\"\"\"\n",
        "cudaError_t err = cudaMalloc(&devicePtr, size);\n",
        "if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "    // Handle error (e.g., clean up resources, exit)\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Check kernel launches: Use cudaGetLastError right after the kernel launch to detect any errors.\n",
        "\n",
        "\"\"\"\n",
        "kernel<<<gridSize, blockSize>>>(parameters);\n",
        "cudaError_t err = cudaGetLastError();\n",
        "if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"Kernel Launch Error: %s\\n\", cudaGetErrorString(err));\n",
        "    // Handle error (e.g., clean up resources, exit)\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Synchronize and check for runtime errors: Use cudaDeviceSynchronize to ensure all preceding operations are complete\n",
        "# and check for errors that occurred during execution.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "err = cudaDeviceSynchronize();\n",
        "if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"Post-Kernel Synchronization Error: %s\\n\", cudaGetErrorString(err));\n",
        "    // Handle error (e.g., clean up resources, exit)\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RYdRBoA5fg1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}